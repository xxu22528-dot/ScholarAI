# agent.py
from typing import List, Dict, Optional
from openai import OpenAI

class ResearchAgent:
    def __init__(self, name: str, system_prompt: str, model: str, api_key: str, base_url: str = None):
        """
        åˆå§‹åŒ–ç§‘ç ”ä»£ç†äºº
        :param name: åå­— (e.g. "è®ºæ–‡ç²¾è¯»åŠ©æ‰‹")
        :param system_prompt: äººè®¾ (e.g. "ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„ç§‘ç ”ä¸“å®¶...")
        :param model: æ¨¡å‹åç§° (e.g. "gpt-4o", "deepseek-chat")
        :param api_key: API å¯†é’¥
        :param base_url: æ¨¡å‹æœåŠ¡å•†åœ°å€
        """
        self.name = name
        self.model = model
        self.system_prompt = system_prompt
        
        # 1. åˆå§‹åŒ–å®¢æˆ·ç«¯ (æ”¯æŒå¤šæ¨¡å‹çš„æ ¸å¿ƒ)
        if base_url:
            self.client = OpenAI(api_key=api_key, base_url=base_url)
        else:
            self.client = OpenAI(api_key=api_key) # é»˜è®¤è¿ OpenAI
            
        # 2. åˆå§‹åŒ–è®°å¿†
        self.history: List[Dict] = [
            {"role": "system", "content": system_prompt}
        ]

    def chat(self, user_input: str, image_base64: Optional[str] = None) -> str:
        """
        æ ¸å¿ƒå¯¹è¯å‡½æ•°
        :param user_input: ç”¨æˆ·çš„æ–‡å­—è¾“å…¥
        :param image_base64: å›¾ç‰‡çš„ Base64 ç¼–ç å­—ç¬¦ä¸² (å¯é€‰)
        """
        # A. æ„å»ºæ¶ˆæ¯å†…å®¹
        if image_base64:
            # --- è§†è§‰æ¨¡å¼ ---
            # å¤§å¤šæ•°å…¼å®¹ OpenAI è§†è§‰æ¥å£çš„æ¨¡å‹éƒ½æ¥å—è¿™ç§æ ¼å¼
            content = [
                {"type": "text", "text": user_input},
                {
                    "type": "image_url", 
                    "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
                }
            ]
        else:
            # --- çº¯æ–‡æœ¬æ¨¡å¼ ---
            content = user_input

        # B. ç”¨æˆ·æ¶ˆæ¯å…¥æ ˆ
        self.history.append({"role": "user", "content": content})

        try:
            # C. è°ƒç”¨ API
            response = self.client.chat.completions.create(
                model=self.model,
                messages=self.history,
                stream=False, # æš‚æ—¶ä¸ä½¿ç”¨æµå¼è¾“å‡ºï¼Œä¿æŒé€»è¾‘ç®€å•
            )
            
            reply = response.choices[0].message.content
            
            # D. AI å›å¤å…¥æ ˆ
            # æ³¨æ„ï¼šå³ä½¿è¾“å…¥æ˜¯å¤æ‚çš„å›¾æ–‡ç»“æ„ï¼ŒAI çš„å›å¤é€šå¸¸åªæ˜¯çº¯æ–‡æœ¬
            self.history.append({"role": "assistant", "content": reply})
            
            return reply

        except Exception as e:
            error_msg = f"âŒ æ¥å£è°ƒç”¨å¤±è´¥: {str(e)}"
            # å‡ºé”™æ—¶ä¸è®°å½•è¿›å†å²ï¼Œé˜²æ­¢æ±¡æŸ“è®°å¿†
            self.history.pop() 
            return error_msg

    def clear_memory(self):
        """æ¸…ç©ºå¯¹è¯å†å²ï¼Œé‡ç½®ä¸ºåˆå§‹çŠ¶æ€"""
        self.history = [
            {"role": "system", "content": self.system_prompt}
        ]
    def summarize(self, context: str, output_format: str = "markdown") -> str:
        """
        ä¸“é—¨ç”¨äºç”Ÿæˆæ€»ç»“æˆ–æŠ¥å‘Š
        """
        prompt = f"""
        è¯·æ ¹æ®ä»¥ä¸‹å¯¹è¯è®°å½•ï¼Œæ•´ç†ä¸€ä»½ç»“æ„åŒ–çš„ç§‘ç ”çºªè¦ã€‚
        
        ã€å¯¹è¯è®°å½•ã€‘
        {context}
        
        ã€è¦æ±‚ã€‘
        1. ä½¿ç”¨ {output_format} æ ¼å¼ã€‚
        2. åŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š
           - ğŸ’¡ æ ¸å¿ƒè§‚ç‚¹æ‘˜è¦ (Abstract)
           - âš”ï¸ ä¸»è¦äº‰è®®/è®¨è®ºè¿‡ç¨‹,é‡ç‚¹è®°å½•userçš„é—®é¢˜ä»¥åŠè®¨è®ºå‡ºçš„ç»“è®º (Discussion)
           - ğŸ“Œ ä¸‹ä¸€æ­¥å»ºè®®æˆ–ç»“è®º (Conclusion)
        3. è®°å½•å…¨é¢ç»†è‡´ã€‚
        """
        
        # ä¸´æ—¶æ„å»ºä¸€æ¡æ¶ˆæ¯ï¼Œä¸å½±å“é•¿æœŸè®°å¿†
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€åä¸“ä¸šçš„å­¦æœ¯ç¼–è¾‘ï¼Œæ“…é•¿æ•´ç†ä¼šè®®çºªè¦ã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                stream=False
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {str(e)}"

def main():
    """æµ‹è¯•ä»£ç """
    agent = ResearchAgent(
        name="è®ºæ–‡ç²¾è¯»åŠ©æ‰‹",
        system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„ç§‘ç ”ä¸“å®¶ï¼Œèƒ½ä»è®ºæ–‡ä¸­æå–æœ‰æ•ˆçš„ä¿¡æ¯ï¼Œå¹¶ç»™å‡ºç›¸åº”çš„å»ºè®®ã€‚",
        model="qwen3-vl-flash",
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        api_key="sk-xxx"
    )
    print(agent.chat("è¯·ç»™æˆ‘ä¸€ä¸ªå…³äºæœºå™¨å­¦ä¹ çš„è®ºæ–‡"))


    # client = OpenAI(
    #     # è‹¥æ²¡æœ‰é…ç½®ç¯å¢ƒå˜é‡ï¼Œè¯·ç”¨ç™¾ç‚¼API Keyå°†ä¸‹è¡Œæ›¿æ¢ä¸ºï¼šapi_key="sk-xxx"
    #     api_key="sk-xxx",
    #     base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    # )
    # completion = client.chat.completions.create(
    #     # æ¨¡å‹åˆ—è¡¨ï¼šhttps://help.aliyun.com/zh/model-studio/getting-started/models
    #     model="qwen-plus",
    #     messages=[
    #         {"role": "system", "content": "You are a helpful assistant."},
    #         {"role": "user", "content": "ä½ æ˜¯è°ï¼Ÿ"},
    #     ]
    # )
    # completion = client.chat.completions.create(
    #     model="qwen-vl-plus",  # æ­¤å¤„ä»¥qwen-vl-plusä¸ºä¾‹ï¼Œå¯æŒ‰éœ€æ›´æ¢æ¨¡å‹åç§°ã€‚æ¨¡å‹åˆ—è¡¨ï¼šhttps://help.aliyun.com/zh/model-studio/getting-started/models
    #     messages=[{"role": "user","content": [
    #             {"type": "image_url",
    #             "image_url": {"url": "https://dashscope.oss-cn-beijing.aliyuncs.com/images/dog_and_girl.jpeg"}},
    #             {"type": "text", "text": "è¿™æ˜¯ä»€ä¹ˆ"},
    #             ]}]
    #     )
    #print(completion.model_dump_json().message.content)

if __name__ == "__main__":
    main()